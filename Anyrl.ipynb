{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anyrl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyHaski/DL_AtariRainbow/blob/master/Anyrl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GzKRIRNUhzh",
        "colab_type": "code",
        "outputId": "caf0ccbe-7ea9-4d50-e5a4-b49241e9178b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsT1hn__UWop",
        "colab_type": "code",
        "outputId": "80f0cb1d-1ae0-4cd8-8640-5c0c158f4af6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install anyrl gym-remote\n",
        "!pip install pyvirtualdisplay > /dev/null 2>&1\n",
        "!pip install pyglet==1.3.1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting anyrl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/07/8924a62b35dfb681d88c148de055059ccc8adf1759551281aae733bdfb64/anyrl-0.12.23-py3-none-any.whl (89kB)\n",
            "\r\u001b[K     |███▋                            | 10kB 26.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.4MB/s \n",
            "\u001b[?25hCollecting gym-remote\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/f1/03a77a1c630c2029720a7d23e43c593bb68b8d74b34d68471e57a9bc3580/gym_remote-1.0.2.tar.gz\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from anyrl) (1.17.4)\n",
            "Collecting pandas<0.24.0,>=0.20.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/d8/feeb346d41f181e83fba45224ab14a8d8af019b48af742e047f3845d8cff/pandas-0.23.4-cp36-cp36m-manylinux1_x86_64.whl (8.9MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9MB 15.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from anyrl) (1.2.2)\n",
            "Collecting gym<0.11.0,>=0.9.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/04/70d4901b7105082c9742acd64728342f6da7cd471572fd0660a73f9cfe27/gym-0.10.11.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 43.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gym-remote) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas<0.24.0,>=0.20.0->anyrl) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas<0.24.0,>=0.20.0->anyrl) (2018.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym<0.11.0,>=0.9.6->anyrl) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym<0.11.0,>=0.9.6->anyrl) (1.12.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym<0.11.0,>=0.9.6->anyrl) (1.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gym-remote) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gym-remote) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gym-remote) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gym-remote) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym<0.11.0,>=0.9.6->anyrl) (0.16.0)\n",
            "Building wheels for collected packages: gym-remote, gym\n",
            "  Building wheel for gym-remote (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym-remote: filename=gym_remote-1.0.2-cp36-none-any.whl size=1270 sha256=7cd93a3c0bc45a5d0ad4b0faa162a3a75bf98a9ab0681948b4dacba880ae8bc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/e4/0d/76490229e428fd3b7586da4f3040336a4ac4684ae3b3822b4b\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.10.11-cp36-none-any.whl size=1588314 sha256=e2fd730104bb5cb4f50f4ebea8a59f21c7ada13c388dbbd67f5f9d771421a74c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/eb/1f/22c4124f3c64943aa0646daf4612b1c1f00f27d89b81304ebd\n",
            "Successfully built gym-remote gym\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.25.0; python_version >= \"3.0\", but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas, gym, anyrl, gym-remote\n",
            "  Found existing installation: pandas 0.25.3\n",
            "    Uninstalling pandas-0.25.3:\n",
            "      Successfully uninstalled pandas-0.25.3\n",
            "  Found existing installation: gym 0.15.4\n",
            "    Uninstalling gym-0.15.4:\n",
            "      Successfully uninstalled gym-0.15.4\n",
            "Successfully installed anyrl-0.12.23 gym-0.10.11 gym-remote-1.0.2 pandas-0.23.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pyglet==1.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/02/e8c21dcce1fd19b57c4c5de134306fa0eb7e507df352f7265b786f608e54/pyglet-1.3.1-py2.py3-none-any.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 5.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 5.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 6.0MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 5.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 5.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 153kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 163kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 174kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 184kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 194kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 204kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 215kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 235kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 245kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 256kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 266kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 276kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 296kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 307kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 317kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 327kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 337kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 348kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 358kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 368kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 378kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 389kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 399kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 409kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 419kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 430kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 440kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 450kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 460kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 471kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 481kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 491kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 501kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 512kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 522kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 532kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 542kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 552kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 563kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 573kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 583kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 593kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 604kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 614kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 624kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 634kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 645kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 655kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 665kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 675kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 686kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 696kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 706kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 716kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 727kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 737kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 747kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 757kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 768kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 778kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 788kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 798kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 808kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 819kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 829kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 839kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 849kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 860kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 870kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 880kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 890kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 901kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 911kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 921kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 931kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 942kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 952kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 962kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 972kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 983kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 993kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.0MB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.3.1) (0.16.0)\n",
            "Installing collected packages: pyglet\n",
            "  Found existing installation: pyglet 1.3.2\n",
            "    Uninstalling pyglet-1.3.2:\n",
            "      Successfully uninstalled pyglet-1.3.2\n",
            "Successfully installed pyglet-1.3.1\n",
            "Collecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/28/c45d8b54c1339f9644b87663945e54a8503cfef59cf0f65b3ff5dd17cf64/setuptools-42.0.2-py2.py3-none-any.whl (583kB)\n",
            "\u001b[K     |████████████████████████████████| 583kB 4.7MB/s \n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.25.0; python_version >= \"3.0\", but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Found existing installation: setuptools 42.0.1\n",
            "    Uninstalling setuptools-42.0.1:\n",
            "      Successfully uninstalled setuptools-42.0.1\n",
            "Successfully installed setuptools-42.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7g6cerfTlGW",
        "colab_type": "code",
        "outputId": "a0c6407d-717e-4580-a5a6-51bda01c4452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import random\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from IPython import display as ipythondispla\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7dYM4lBTkew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, '/content/drive/My Drive/videoAnyrl', resume=True )\n",
        "  return env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q28xoaCVBFG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class DQN:\n",
        "    \"\"\"\n",
        "    Train TFQNetwork models using Q-learning.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, online_net, target_net, discount=0.99):\n",
        "        \"\"\"\n",
        "        Create a Q-learning session.\n",
        "        Args:\n",
        "          online_net: the online TFQNetwork.\n",
        "          target_net: the target TFQNetwork.\n",
        "          discount: the per-step discount factor.\n",
        "        \"\"\"\n",
        "        self.online_net = online_net\n",
        "        self.target_net = target_net\n",
        "        self.discount = discount\n",
        "\n",
        "        obs_shape = (None,) + online_net.obs_vectorizer.out_shape\n",
        "        self.obses_ph = tf.placeholder(online_net.input_dtype, shape=obs_shape)\n",
        "        self.actions_ph = tf.placeholder(tf.int32, shape=(None,))\n",
        "        self.rews_ph = tf.placeholder(tf.float32, shape=(None,))\n",
        "        self.new_obses_ph = tf.placeholder(online_net.input_dtype, shape=obs_shape)\n",
        "        self.terminals_ph = tf.placeholder(tf.bool, shape=(None,))\n",
        "        self.discounts_ph = tf.placeholder(tf.float32, shape=(None,))\n",
        "        self.weights_ph = tf.placeholder(tf.float32, shape=(None,))\n",
        "\n",
        "        losses = online_net.transition_loss(target_net, self.obses_ph, self.actions_ph,\n",
        "                                            self.rews_ph, self.new_obses_ph, self.terminals_ph,\n",
        "                                            self.discounts_ph)\n",
        "        self.losses = self.weights_ph * losses\n",
        "        self.loss = tf.reduce_mean(self.losses)\n",
        "\n",
        "        assigns = []\n",
        "        for dst, src in zip(target_net.variables, online_net.variables):\n",
        "            assigns.append(tf.assign(dst, src))\n",
        "        self.update_target = tf.group(*assigns)\n",
        "\n",
        "    def feed_dict(self, transitions):\n",
        "        \"\"\"\n",
        "        Generate a feed_dict that feeds the batch of\n",
        "        transitions to the DQN loss terms.\n",
        "        Args:\n",
        "          transition: a sequence of transition dicts, as\n",
        "            defined in anyrl.rollouts.ReplayBuffer.\n",
        "        Returns:\n",
        "          A dict which can be fed to tf.Session.run().\n",
        "        \"\"\"\n",
        "        obs_vect = self.online_net.obs_vectorizer\n",
        "        res = {\n",
        "            self.obses_ph: obs_vect.to_vecs([t['obs'] for t in transitions]),\n",
        "            self.actions_ph: [t['model_outs']['actions'][0] for t in transitions],\n",
        "            self.rews_ph: [self._discounted_rewards(t['rewards']) for t in transitions],\n",
        "            self.terminals_ph: [t['new_obs'] is None for t in transitions],\n",
        "            self.discounts_ph: [(self.discount ** len(t['rewards'])) for t in transitions],\n",
        "            self.weights_ph: [t['weight'] for t in transitions]\n",
        "        }\n",
        "        new_obses = []\n",
        "        for trans in transitions:\n",
        "            if trans['new_obs'] is None:\n",
        "                new_obses.append(trans['obs'])\n",
        "            else:\n",
        "                new_obses.append(trans['new_obs'])\n",
        "        res[self.new_obses_ph] = obs_vect.to_vecs(new_obses)\n",
        "        return res\n",
        "\n",
        "    def optimize(self, learning_rate=6.25e-5, epsilon=1.5e-4, **adam_kwargs):\n",
        "        \"\"\"\n",
        "        Create a TF Op that optimizes the objective.\n",
        "        Args:\n",
        "          learning_rate: the Adam learning rate.\n",
        "          epsilon: the Adam epsilon.\n",
        "        \"\"\"\n",
        "        optim = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=epsilon, **adam_kwargs)\n",
        "        return optim.minimize(self.loss)\n",
        "\n",
        "    def train(self,\n",
        "              num_steps,\n",
        "              player,\n",
        "              replay_buffer,\n",
        "              optimize_op,\n",
        "              train_interval=1,\n",
        "              target_interval=8192,\n",
        "              batch_size=32,\n",
        "              min_buffer_size=20000,\n",
        "              tf_schedules=(),\n",
        "              handle_ep=lambda steps, rew: None,\n",
        "              timeout=None):\n",
        "        \"\"\"\n",
        "        Run an automated training loop.\n",
        "        This is meant to provide a convenient way to run a\n",
        "        standard training loop without any modifications.\n",
        "        You may get more flexibility by writing your own\n",
        "        training loop.\n",
        "        Args:\n",
        "          num_steps: the number of timesteps to run.\n",
        "          player: the Player for gathering experience.\n",
        "          replay_buffer: the ReplayBuffer for experience.\n",
        "          optimize_op: a TF Op to optimize the model.\n",
        "          train_interval: timesteps per training step.\n",
        "          target_interval: number of timesteps between\n",
        "            target network updates.\n",
        "          batch_size: the size of experience mini-batches.\n",
        "          min_buffer_size: minimum replay buffer size\n",
        "            before training is performed.\n",
        "          tf_schedules: a sequence of TFSchedules that are\n",
        "            updated with the number of steps taken.\n",
        "          handle_ep: called with information about every\n",
        "            completed episode.\n",
        "          timeout: if set, this is a number of seconds\n",
        "            after which the training loop should exit.\n",
        "        \"\"\"\n",
        "        \n",
        "        \n",
        "        sess = self.online_net.session\n",
        "        \n",
        "        tnloss = tf.summary.scalar(name='loss', tensor=tf.reduce_mean(self.loss))\n",
        "        tnrewsph = tf.summary.scalar(name='rews_ph', tensor=tf.reduce_mean(self.rews_ph))\n",
        "        tndiscountsph = tf.summary.scalar(name='discounts_ph', tensor=tf.reduce_mean(self.discounts_ph))\n",
        "        tnweightsph = tf.summary.scalar(name='weights_ph', tensor=tf.reduce_mean(self.weights_ph))\n",
        "        tnlosses = tf.summary.scalar(name='losses', tensor=tf.reduce_mean(self.losses))\n",
        "\n",
        "        merge = tf.summary.merge([tnloss,tnrewsph,tndiscountsph,tnweightsph,tnlosses])\n",
        "        train_writer = tf.summary.FileWriter( '/content/drive/My Drive/AN/logs/2/train', sess.graph)\n",
        "        sess.run(self.update_target)\n",
        "        steps_taken = 0\n",
        "        next_target_update = target_interval\n",
        "        next_train_step = train_interval\n",
        "        start_time = time.time()\n",
        "\n",
        "        while steps_taken < num_steps:\n",
        "            if timeout is not None and time.time() - start_time > timeout:\n",
        "                return\n",
        "            transitions = player.play()\n",
        "            for trans in transitions:\n",
        "                if trans['is_last']:\n",
        "                    handle_ep(trans['episode_step'] + 1, trans['total_reward'])\n",
        "                replay_buffer.add_sample(trans)\n",
        "                steps_taken += 1\n",
        "                for sched in tf_schedules:\n",
        "                    sched.add_time(sess, 1)\n",
        "                if replay_buffer.size >= min_buffer_size and steps_taken >= next_train_step:\n",
        "                    next_train_step = steps_taken + train_interval\n",
        "                    batch = replay_buffer.sample(batch_size)\n",
        "\n",
        "                    _, losses, summary = sess.run((optimize_op, self.losses, merge),\n",
        "                                         feed_dict=self.feed_dict(batch))\n",
        "                    \n",
        "                    train_writer.add_summary(summary, steps_taken)\n",
        "                    replay_buffer.update_weights(batch, losses)\n",
        "                if steps_taken >= next_target_update:\n",
        "                    next_target_update = steps_taken + target_interval\n",
        "                    sess.run(self.update_target)\n",
        "\n",
        "    def _discounted_rewards(self, rews):\n",
        "        res = 0\n",
        "        for i, rew in enumerate(rews):\n",
        "            res += rew * (self.discount ** i)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vq_lTHZV3iW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afc4j-0zMTC2",
        "colab_type": "code",
        "outputId": "f57367a2-e92e-4681-9dcf-c1d3c3d1c9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "\"\"\"\n",
        "Train an agent on Sonic using an open source Rainbow DQN\n",
        "implementation.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from functools import partial\n",
        "#from anyrl.algos import DQN\n",
        "from anyrl.envs import batched_gym_env\n",
        "from anyrl.envs.wrappers import BatchedFrameStack, DownsampleEnv, GrayscaleEnv\n",
        "from anyrl.models import rainbow_models\n",
        "from anyrl.rollouts import BatchedPlayer, PrioritizedReplayBuffer, NStepPlayer\n",
        "from anyrl.spaces import gym_space_vectorizer\n",
        "from anyrl.utils import tf_state\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "REWARD_HISTORY = 10\n",
        "\n",
        "def make_env():\n",
        "    \"\"\"\n",
        "    Create an environment with some standard wrappers.\n",
        "    \"\"\"\n",
        "    env = wrap_env(gym.make('SpaceInvaders-v0'))\n",
        "    return GrayscaleEnv(DownsampleEnv(env, 2))\n",
        "\n",
        "def main():\n",
        "    \n",
        "    env = batched_gym_env([partial(make_env)]*2)\n",
        "\n",
        "    env = BatchedFrameStack(env, num_images=4, concat=False)\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True # pylint: disable=E1101\n",
        "    \n",
        "    \n",
        "    with tf.Session(config=config) as sess:  \n",
        "        \n",
        "        online, target=rainbow_models(sess,\n",
        "                              env.action_space.n,\n",
        "                              gym_space_vectorizer(env.observation_space),\n",
        "                              min_val=-10,\n",
        "                              max_val=10)\n",
        "        \n",
        "        dqn = DQN(online,target)\n",
        "        player = NStepPlayer(BatchedPlayer(env, dqn.online_net), 3)\n",
        "        optimize = dqn.optimize(learning_rate=6.25e-5)\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        reward_hist = []\n",
        "        total_steps = 0\n",
        "\n",
        "        def _handle_ep(steps, rew):\n",
        "            nonlocal total_steps\n",
        "            total_steps += steps\n",
        "            reward_hist.append(rew)\n",
        "            if len(reward_hist) == REWARD_HISTORY:\n",
        "                print('%d steps: mean=%f' % (total_steps, sum(reward_hist) / len(reward_hist)))\n",
        "                reward_hist.clear()\n",
        "                \n",
        "        tf_state.load_vars(sess,'/content/drive/My Drive/AN/anyrlModel',conditional=True,relaxed=True) \n",
        "        dqn.train(num_steps=1000000, \n",
        "                  player=player,\n",
        "                  replay_buffer=PrioritizedReplayBuffer(50000, 0.5, 0.4, epsilon=0.1),\n",
        "                  optimize_op=optimize,\n",
        "                  train_interval=1,\n",
        "                  target_interval=8192,\n",
        "                  batch_size=32,\n",
        "                  min_buffer_size=20000,\n",
        "                  timeout=3600*10,\n",
        "                  handle_ep=_handle_ep)\n",
        "        \n",
        "        saver = tf.train.Saver()\n",
        "        saver.save(sess, '/content/drive/My Drive/TF/tfModel')\n",
        "        tf_state.save_vars(sess,'/content/drive/My Drive/AN/anyrlModel')\n",
        "    env.close()\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "      main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "State path does not exist: /content/drive/My Drive/AN/anyrlModel\n",
            "6732 steps: mean=150.500000\n",
            "13842 steps: mean=124.000000\n",
            "20395 steps: mean=128.500000\n",
            "28810 steps: mean=265.500000\n",
            "36941 steps: mean=152.500000\n",
            "45030 steps: mean=156.000000\n",
            "54243 steps: mean=204.500000\n",
            "61118 steps: mean=150.500000\n",
            "69537 steps: mean=249.500000\n",
            "76955 steps: mean=208.500000\n",
            "85252 steps: mean=194.000000\n",
            "93263 steps: mean=189.500000\n",
            "101162 steps: mean=146.500000\n",
            "108679 steps: mean=187.500000\n",
            "114197 steps: mean=135.000000\n",
            "120319 steps: mean=171.500000\n",
            "127498 steps: mean=199.000000\n",
            "135285 steps: mean=232.500000\n",
            "142269 steps: mean=228.000000\n",
            "149002 steps: mean=203.500000\n",
            "156224 steps: mean=236.000000\n",
            "164098 steps: mean=267.500000\n",
            "171140 steps: mean=255.000000\n",
            "178575 steps: mean=254.500000\n",
            "186619 steps: mean=277.000000\n",
            "194673 steps: mean=264.000000\n",
            "201633 steps: mean=213.500000\n",
            "210560 steps: mean=331.500000\n",
            "217626 steps: mean=180.000000\n",
            "226659 steps: mean=356.000000\n",
            "233666 steps: mean=235.500000\n",
            "240592 steps: mean=246.500000\n",
            "248519 steps: mean=298.500000\n",
            "255871 steps: mean=262.500000\n",
            "262760 steps: mean=236.500000\n",
            "271247 steps: mean=285.500000\n",
            "279237 steps: mean=290.500000\n",
            "288110 steps: mean=317.500000\n",
            "295576 steps: mean=237.000000\n",
            "302473 steps: mean=234.000000\n",
            "311645 steps: mean=317.500000\n",
            "319098 steps: mean=278.000000\n",
            "326479 steps: mean=255.000000\n",
            "334475 steps: mean=276.000000\n",
            "341843 steps: mean=235.000000\n",
            "350309 steps: mean=274.500000\n",
            "358573 steps: mean=316.500000\n",
            "366486 steps: mean=314.000000\n",
            "374533 steps: mean=275.500000\n",
            "383812 steps: mean=398.500000\n",
            "393499 steps: mean=328.500000\n",
            "401656 steps: mean=268.500000\n",
            "410218 steps: mean=306.000000\n",
            "420400 steps: mean=374.000000\n",
            "428597 steps: mean=272.000000\n",
            "437461 steps: mean=327.500000\n",
            "445727 steps: mean=289.500000\n",
            "454775 steps: mean=360.000000\n",
            "464121 steps: mean=303.000000\n",
            "473615 steps: mean=350.500000\n",
            "481472 steps: mean=255.000000\n",
            "489411 steps: mean=291.500000\n",
            "497471 steps: mean=269.000000\n",
            "506803 steps: mean=356.000000\n",
            "515040 steps: mean=254.500000\n",
            "523955 steps: mean=302.000000\n",
            "532745 steps: mean=309.000000\n",
            "540712 steps: mean=277.500000\n",
            "547582 steps: mean=228.500000\n",
            "557189 steps: mean=371.500000\n",
            "564996 steps: mean=277.000000\n",
            "572492 steps: mean=273.000000\n",
            "581839 steps: mean=326.500000\n",
            "590453 steps: mean=315.000000\n",
            "598902 steps: mean=324.500000\n",
            "607555 steps: mean=297.000000\n",
            "614972 steps: mean=289.000000\n",
            "622290 steps: mean=236.000000\n",
            "630013 steps: mean=261.000000\n",
            "638482 steps: mean=249.000000\n",
            "645777 steps: mean=233.500000\n",
            "652561 steps: mean=235.000000\n",
            "661919 steps: mean=375.500000\n",
            "670290 steps: mean=303.500000\n",
            "678259 steps: mean=264.000000\n",
            "686592 steps: mean=314.000000\n",
            "695054 steps: mean=323.000000\n",
            "704540 steps: mean=371.000000\n",
            "713795 steps: mean=334.000000\n",
            "721358 steps: mean=271.500000\n",
            "728561 steps: mean=263.000000\n",
            "736508 steps: mean=284.000000\n",
            "743442 steps: mean=242.000000\n",
            "751538 steps: mean=278.000000\n",
            "760594 steps: mean=282.500000\n",
            "768908 steps: mean=266.500000\n",
            "777483 steps: mean=314.500000\n",
            "785180 steps: mean=221.000000\n",
            "793914 steps: mean=331.000000\n",
            "802281 steps: mean=280.500000\n",
            "810383 steps: mean=308.500000\n",
            "817556 steps: mean=197.500000\n",
            "825012 steps: mean=257.500000\n",
            "832901 steps: mean=283.500000\n",
            "841544 steps: mean=325.500000\n",
            "850016 steps: mean=305.500000\n",
            "857397 steps: mean=265.000000\n",
            "864703 steps: mean=266.000000\n",
            "872444 steps: mean=293.000000\n",
            "880704 steps: mean=320.000000\n",
            "887947 steps: mean=270.500000\n",
            "896450 steps: mean=315.000000\n",
            "904023 steps: mean=272.500000\n",
            "911533 steps: mean=234.000000\n",
            "918867 steps: mean=278.000000\n",
            "925744 steps: mean=250.000000\n",
            "934293 steps: mean=315.500000\n",
            "943473 steps: mean=332.500000\n",
            "951819 steps: mean=301.500000\n",
            "960122 steps: mean=318.500000\n",
            "967287 steps: mean=231.000000\n",
            "974095 steps: mean=198.000000\n",
            "982550 steps: mean=292.000000\n",
            "991811 steps: mean=325.500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dp3iWaYcDZc",
        "colab_type": "code",
        "outputId": "17bdd780-1ea0-432d-a822-f8c27369bfc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-08 13:34:42--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 50.17.165.171, 52.206.235.84, 52.4.11.55, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|50.17.165.171|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab   0%[                    ]  96.97K   393KB/s               \r        ngrok-stabl   6%[>                   ] 889.81K  1.76MB/s               \r       ngrok-stable  48%[========>           ]   6.37M  8.60MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  14.4MB/s    in 0.9s    \n",
            "\n",
            "2019-12-08 13:34:43 (14.4 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v-GqeiDcFLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = './drive/My Drive/AN/logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4TZSrYHcvhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3punndnKcyF0",
        "colab_type": "code",
        "outputId": "a9ba84db-a676-41ee-9ca3-9786d959f0bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://fe390960.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7jS6xaaj4Er",
        "colab_type": "code",
        "outputId": "908947d8-d4a3-4841-8644-5857391df5e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!tensorboard --logdir='./drive/My Drive/AN/logs' "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorBoard 1.15.0 at http://56172a9b9d94:6006/ (Press CTRL+C to quit)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}