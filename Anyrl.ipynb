{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anyrl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyHaski/DL_AtariRainbow/blob/master/Anyrl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GzKRIRNUhzh",
        "colab_type": "code",
        "outputId": "89db295c-08f7-4a91-e44c-febe5fcb1b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsT1hn__UWop",
        "colab_type": "code",
        "outputId": "67cd17d4-5d63-4cf5-e2d6-7c034ebbd7ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install anyrl gym-remote\n",
        "!pip install pyvirtualdisplay > /dev/null 2>&1\n",
        "!pip install pyglet==1.3.1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting anyrl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/07/8924a62b35dfb681d88c148de055059ccc8adf1759551281aae733bdfb64/anyrl-0.12.23-py3-none-any.whl (89kB)\n",
            "\r\u001b[K     |███▋                            | 10kB 30.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.4MB/s \n",
            "\u001b[?25hCollecting gym-remote\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/f1/03a77a1c630c2029720a7d23e43c593bb68b8d74b34d68471e57a9bc3580/gym_remote-1.0.2.tar.gz\n",
            "Collecting gym<0.11.0,>=0.9.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/04/70d4901b7105082c9742acd64728342f6da7cd471572fd0660a73f9cfe27/gym-0.10.11.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from anyrl) (1.2.2)\n",
            "Collecting pandas<0.24.0,>=0.20.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/d8/feeb346d41f181e83fba45224ab14a8d8af019b48af742e047f3845d8cff/pandas-0.23.4-cp36-cp36m-manylinux1_x86_64.whl (8.9MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9MB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from anyrl) (1.17.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gym-remote) (2.21.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym<0.11.0,>=0.9.6->anyrl) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym<0.11.0,>=0.9.6->anyrl) (1.12.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym<0.11.0,>=0.9.6->anyrl) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas<0.24.0,>=0.20.0->anyrl) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas<0.24.0,>=0.20.0->anyrl) (2.6.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gym-remote) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gym-remote) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gym-remote) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gym-remote) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym<0.11.0,>=0.9.6->anyrl) (0.16.0)\n",
            "Building wheels for collected packages: gym-remote, gym\n",
            "  Building wheel for gym-remote (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym-remote: filename=gym_remote-1.0.2-cp36-none-any.whl size=1270 sha256=70766dfa5bb05ebc449f572a63173c1d299b2f805cb52f8f8085716fc1b209ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/e4/0d/76490229e428fd3b7586da4f3040336a4ac4684ae3b3822b4b\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.10.11-cp36-none-any.whl size=1588314 sha256=30fbbe058a4f2d6c00b6cb901115c3e7dd7a3e2a19fdfaa7edbf0db2e84a71e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/eb/1f/22c4124f3c64943aa0646daf4612b1c1f00f27d89b81304ebd\n",
            "Successfully built gym-remote gym\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.25.0; python_version >= \"3.0\", but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gym, pandas, anyrl, gym-remote\n",
            "  Found existing installation: gym 0.15.4\n",
            "    Uninstalling gym-0.15.4:\n",
            "      Successfully uninstalled gym-0.15.4\n",
            "  Found existing installation: pandas 0.25.3\n",
            "    Uninstalling pandas-0.25.3:\n",
            "      Successfully uninstalled pandas-0.25.3\n",
            "Successfully installed anyrl-0.12.23 gym-0.10.11 gym-remote-1.0.2 pandas-0.23.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pyglet==1.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/02/e8c21dcce1fd19b57c4c5de134306fa0eb7e507df352f7265b786f608e54/pyglet-1.3.1-py2.py3-none-any.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 2.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 6.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133kB 4.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143kB 4.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 153kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 163kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 174kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 184kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 194kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 204kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 215kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 235kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 245kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 256kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 266kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 276kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 296kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 307kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 317kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 327kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 337kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 348kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 358kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 368kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 378kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 389kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 399kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 409kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 419kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 430kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 440kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 450kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 460kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 471kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 481kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 491kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 501kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 512kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 522kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 532kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 542kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 552kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 563kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 573kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 583kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 593kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 604kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 614kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 624kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 634kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 645kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 655kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 665kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 675kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 686kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 696kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 706kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 716kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 727kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 737kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 747kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 757kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 768kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 778kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 788kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 798kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 808kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 819kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 829kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 839kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 849kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 860kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 870kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 880kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 890kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 901kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 911kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 921kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 931kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 942kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 952kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 962kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 972kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 983kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 993kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.0MB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.3.1) (0.16.0)\n",
            "Installing collected packages: pyglet\n",
            "  Found existing installation: pyglet 1.3.2\n",
            "    Uninstalling pyglet-1.3.2:\n",
            "      Successfully uninstalled pyglet-1.3.2\n",
            "Successfully installed pyglet-1.3.1\n",
            "Collecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/28/c45d8b54c1339f9644b87663945e54a8503cfef59cf0f65b3ff5dd17cf64/setuptools-42.0.2-py2.py3-none-any.whl (583kB)\n",
            "\u001b[K     |████████████████████████████████| 583kB 5.1MB/s \n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.25.0; python_version >= \"3.0\", but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Found existing installation: setuptools 42.0.1\n",
            "    Uninstalling setuptools-42.0.1:\n",
            "      Successfully uninstalled setuptools-42.0.1\n",
            "Successfully installed setuptools-42.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7g6cerfTlGW",
        "colab_type": "code",
        "outputId": "ac9e6b4f-7c53-430c-8434-52c9579f98d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import random\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from IPython import display as ipythondispla\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7dYM4lBTkew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q28xoaCVBFG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class DQN:\n",
        "    \"\"\"\n",
        "    Train TFQNetwork models using Q-learning.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, online_net, target_net, discount=0.99):\n",
        "        \"\"\"\n",
        "        Create a Q-learning session.\n",
        "        Args:\n",
        "          online_net: the online TFQNetwork.\n",
        "          target_net: the target TFQNetwork.\n",
        "          discount: the per-step discount factor.\n",
        "        \"\"\"\n",
        "        self.online_net = online_net\n",
        "        self.target_net = target_net\n",
        "        self.discount = discount\n",
        "\n",
        "        obs_shape = (None,) + online_net.obs_vectorizer.out_shape\n",
        "        self.obses_ph = tf.placeholder(online_net.input_dtype, shape=obs_shape)\n",
        "        self.actions_ph = tf.placeholder(tf.int32, shape=(None,))\n",
        "        self.rews_ph = tf.placeholder(tf.float32, shape=(None,))\n",
        "        self.new_obses_ph = tf.placeholder(online_net.input_dtype, shape=obs_shape)\n",
        "        self.terminals_ph = tf.placeholder(tf.bool, shape=(None,))\n",
        "        self.discounts_ph = tf.placeholder(tf.float32, shape=(None,))\n",
        "        self.weights_ph = tf.placeholder(tf.float32, shape=(None,))\n",
        "\n",
        "        losses = online_net.transition_loss(target_net, self.obses_ph, self.actions_ph,\n",
        "                                            self.rews_ph, self.new_obses_ph, self.terminals_ph,\n",
        "                                            self.discounts_ph)\n",
        "        self.losses = self.weights_ph * losses\n",
        "        self.loss = tf.reduce_mean(self.losses)\n",
        "\n",
        "        assigns = []\n",
        "        for dst, src in zip(target_net.variables, online_net.variables):\n",
        "            assigns.append(tf.assign(dst, src))\n",
        "        self.update_target = tf.group(*assigns)\n",
        "\n",
        "    def feed_dict(self, transitions):\n",
        "        \"\"\"\n",
        "        Generate a feed_dict that feeds the batch of\n",
        "        transitions to the DQN loss terms.\n",
        "        Args:\n",
        "          transition: a sequence of transition dicts, as\n",
        "            defined in anyrl.rollouts.ReplayBuffer.\n",
        "        Returns:\n",
        "          A dict which can be fed to tf.Session.run().\n",
        "        \"\"\"\n",
        "        obs_vect = self.online_net.obs_vectorizer\n",
        "        res = {\n",
        "            self.obses_ph: obs_vect.to_vecs([t['obs'] for t in transitions]),\n",
        "            self.actions_ph: [t['model_outs']['actions'][0] for t in transitions],\n",
        "            self.rews_ph: [self._discounted_rewards(t['rewards']) for t in transitions],\n",
        "            self.terminals_ph: [t['new_obs'] is None for t in transitions],\n",
        "            self.discounts_ph: [(self.discount ** len(t['rewards'])) for t in transitions],\n",
        "            self.weights_ph: [t['weight'] for t in transitions]\n",
        "        }\n",
        "        new_obses = []\n",
        "        for trans in transitions:\n",
        "            if trans['new_obs'] is None:\n",
        "                new_obses.append(trans['obs'])\n",
        "            else:\n",
        "                new_obses.append(trans['new_obs'])\n",
        "        res[self.new_obses_ph] = obs_vect.to_vecs(new_obses)\n",
        "        return res\n",
        "\n",
        "    def optimize(self, learning_rate=6.25e-5, epsilon=1.5e-4, **adam_kwargs):\n",
        "        \"\"\"\n",
        "        Create a TF Op that optimizes the objective.\n",
        "        Args:\n",
        "          learning_rate: the Adam learning rate.\n",
        "          epsilon: the Adam epsilon.\n",
        "        \"\"\"\n",
        "        optim = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=epsilon, **adam_kwargs)\n",
        "        return optim.minimize(self.loss)\n",
        "\n",
        "    def train(self,\n",
        "              num_steps,\n",
        "              player,\n",
        "              replay_buffer,\n",
        "              optimize_op,\n",
        "              train_interval=1,\n",
        "              target_interval=8192,\n",
        "              batch_size=32,\n",
        "              min_buffer_size=20000,\n",
        "              tf_schedules=(),\n",
        "              handle_ep=lambda steps, rew: None,\n",
        "              timeout=None):\n",
        "        \"\"\"\n",
        "        Run an automated training loop.\n",
        "        This is meant to provide a convenient way to run a\n",
        "        standard training loop without any modifications.\n",
        "        You may get more flexibility by writing your own\n",
        "        training loop.\n",
        "        Args:\n",
        "          num_steps: the number of timesteps to run.\n",
        "          player: the Player for gathering experience.\n",
        "          replay_buffer: the ReplayBuffer for experience.\n",
        "          optimize_op: a TF Op to optimize the model.\n",
        "          train_interval: timesteps per training step.\n",
        "          target_interval: number of timesteps between\n",
        "            target network updates.\n",
        "          batch_size: the size of experience mini-batches.\n",
        "          min_buffer_size: minimum replay buffer size\n",
        "            before training is performed.\n",
        "          tf_schedules: a sequence of TFSchedules that are\n",
        "            updated with the number of steps taken.\n",
        "          handle_ep: called with information about every\n",
        "            completed episode.\n",
        "          timeout: if set, this is a number of seconds\n",
        "            after which the training loop should exit.\n",
        "        \"\"\"\n",
        "        \n",
        "        \n",
        "        sess = self.online_net.session\n",
        "        \n",
        "        tnloss = tf.summary.scalar(name='loss', tensor=tf.reduce_mean(self.loss))\n",
        "        tnrewsph = tf.summary.scalar(name='rews_ph', tensor=tf.reduce_mean(self.rews_ph))\n",
        "        tndiscountsph = tf.summary.scalar(name='discounts_ph', tensor=tf.reduce_mean(self.discounts_ph))\n",
        "        tnweightsph = tf.summary.scalar(name='weights_ph', tensor=tf.reduce_mean(self.weights_ph))\n",
        "        tnlosses = tf.summary.scalar(name='losses', tensor=tf.reduce_mean(self.losses))\n",
        "\n",
        "        merge = tf.summary.merge([tnloss,tnrewsph,tndiscountsph,tnweightsph,tnlosses])\n",
        "        train_writer = tf.summary.FileWriter( './logs/1/train', sess.graph)\n",
        "        sess.run(self.update_target)\n",
        "        steps_taken = 0\n",
        "        next_target_update = target_interval\n",
        "        next_train_step = train_interval\n",
        "        start_time = time.time()\n",
        "\n",
        "        while steps_taken < num_steps:\n",
        "            if timeout is not None and time.time() - start_time > timeout:\n",
        "                return\n",
        "            transitions = player.play()\n",
        "            for trans in transitions:\n",
        "                if trans['is_last']:\n",
        "                    handle_ep(trans['episode_step'] + 1, trans['total_reward'])\n",
        "                replay_buffer.add_sample(trans)\n",
        "                steps_taken += 1\n",
        "                for sched in tf_schedules:\n",
        "                    sched.add_time(sess, 1)\n",
        "                if replay_buffer.size >= min_buffer_size and steps_taken >= next_train_step:\n",
        "                    next_train_step = steps_taken + train_interval\n",
        "                    batch = replay_buffer.sample(batch_size)\n",
        "\n",
        "                    _, losses, summary = sess.run((optimize_op, self.losses, merge),\n",
        "                                         feed_dict=self.feed_dict(batch))\n",
        "                    \n",
        "                    train_writer.add_summary(summary, steps_taken)\n",
        "                    replay_buffer.update_weights(batch, losses)\n",
        "                if steps_taken >= next_target_update:\n",
        "                    next_target_update = steps_taken + target_interval\n",
        "                    sess.run(self.update_target)\n",
        "\n",
        "    def _discounted_rewards(self, rews):\n",
        "        res = 0\n",
        "        for i, rew in enumerate(rews):\n",
        "            res += rew * (self.discount ** i)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vq_lTHZV3iW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afc4j-0zMTC2",
        "colab_type": "code",
        "outputId": "7cefd8dc-44b9-4228-dffe-ecb48275e01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "\"\"\"\n",
        "Train an agent on Sonic using an open source Rainbow DQN\n",
        "implementation.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from functools import partial\n",
        "#from anyrl.algos import DQN\n",
        "from anyrl.envs import batched_gym_env\n",
        "from anyrl.envs.wrappers import BatchedFrameStack, DownsampleEnv, GrayscaleEnv\n",
        "from anyrl.models import rainbow_models\n",
        "from anyrl.rollouts import BatchedPlayer, PrioritizedReplayBuffer, NStepPlayer\n",
        "from anyrl.spaces import gym_space_vectorizer\n",
        "from anyrl.utils import tf_state\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "REWARD_HISTORY = 10\n",
        "\n",
        "def make_env():\n",
        "    \"\"\"\n",
        "    Create an environment with some standard wrappers.\n",
        "    \"\"\"\n",
        "    env = wrap_env(gym.make('SpaceInvaders-v0'))\n",
        "    return GrayscaleEnv(DownsampleEnv(env, 2))\n",
        "\n",
        "def main():\n",
        "    \n",
        "    env = batched_gym_env([partial(make_env)])\n",
        "\n",
        "    env = BatchedFrameStack(env, num_images=4, concat=False)\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True # pylint: disable=E1101\n",
        "    \n",
        "    \n",
        "    with tf.Session(config=config) as sess:  \n",
        "        \n",
        "        online, target=rainbow_models(sess,\n",
        "                              env.action_space.n,\n",
        "                              gym_space_vectorizer(env.observation_space),\n",
        "                              min_val=-200,\n",
        "                              max_val=200)\n",
        "        \n",
        "        dqn = DQN(online,target)\n",
        "        player = NStepPlayer(BatchedPlayer(env, dqn.online_net), 2)\n",
        "        optimize = dqn.optimize(learning_rate=1e-4)\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        reward_hist = []\n",
        "        total_steps = 0\n",
        "\n",
        "        def _handle_ep(steps, rew):\n",
        "            nonlocal total_steps\n",
        "            total_steps += steps\n",
        "            reward_hist.append(rew)\n",
        "            if len(reward_hist) == REWARD_HISTORY:\n",
        "                print('%d steps: mean=%f' % (total_steps, sum(reward_hist) / len(reward_hist)))\n",
        "                reward_hist.clear()\n",
        "                \n",
        "        tf_state.load_vars(sess,'/content/AN/an',conditional=True,relaxed=True) \n",
        "        dqn.train(num_steps=10000000, \n",
        "                  player=player,\n",
        "                  replay_buffer=PrioritizedReplayBuffer(500000, 0.5, 0.4, epsilon=0.1),\n",
        "                  optimize_op=optimize,\n",
        "                  train_interval=1,\n",
        "                  target_interval=8192,\n",
        "                  batch_size=32,\n",
        "                  min_buffer_size=10000,\n",
        "                  timeout=3600*10,\n",
        "                  handle_ep=_handle_ep)\n",
        "        \n",
        "        saver = tf.train.Saver()\n",
        "        saver.save(sess, '/content/TF/tfModels')\n",
        "        tf_state.save_vars(sess,'/content/AN/an')\n",
        "    env.close()\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "      main()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading variables from /content/AN/an ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dp3iWaYcDZc",
        "colab_type": "code",
        "outputId": "b7e1d268-98cc-49bd-befb-632bf93a7543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-07 13:33:52--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.2.208.1, 54.224.175.112, 52.203.255.14, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.2.208.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  18.3MB/s    in 0.7s    \n",
            "\n",
            "2019-12-07 13:33:53 (18.3 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v-GqeiDcFLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = './logs/1/train'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4TZSrYHcvhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3punndnKcyF0",
        "colab_type": "code",
        "outputId": "f59777d7-3877-4aff-891c-2e04741d9879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://dc567da4.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7jS6xaaj4Er",
        "colab_type": "code",
        "outputId": "da3dadcf-ad94-42ab-d8f4-fa30b68d3e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!tensorboard --logdir=./logs/1/train "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}